1) Running parse.pl

- Make sure you have the DBI, Time::Local, Text::CSV and XML::Parser::PerlSAX Perl modules installed.

- Create a MySQL database and perform the following queries:

CREATE TABLE `edge` (
  `fromuser` varchar(255) NOT NULL,
  `touser` varchar(255) NOT NULL,
  `weight` float NOT NULL,
  `article` varchar(255) NOT NULL,
  `sid` varchar(255) NOT NULL
);

CREATE TABLE `weeklyedits` (
  `user` varchar(255) NOT NULL,
  `article` varchar(255) NOT NULL,
  `rsd` float NOT NULL COMMENT 'relative standard deviation of weekly edits'
);

CREATE TABLE `eigenvalue` (
  `article` varchar(255) NOT NULL,
  `lambda1` double NOT NULL COMMENT 'smallest eigenvalue',
  `lambda2` double NOT NULL COMMENT 'second smallest eigenvalue',
  `sid` varchar(255) NOT NULL,
  PRIMARY KEY (`article`,`sid`)
);

CREATE TABLE `eigenvector` (
  `user` varchar(255) NOT NULL,
  `article` varchar(255) NOT NULL,
  `v1` double NOT NULL COMMENT 'vectorelement to the smallest eigenvalue',
  `v2` double NOT NULL COMMENT 'vectorelement to the 2nd smallest eigenvalue',
  `sid` varchar(255) NOT NULL,
  PRIMARY KEY (`user`,`article`,`sid`)
);

CREATE TABLE `entry` (
  `userid` varchar(255) NOT NULL,
  `timestamp` datetime NOT NULL,
  `article` varchar(255) NOT NULL
);

CREATE TABLE `evgen` (
  `sid` varchar(255) NOT NULL,
  `finished` bit(1) NOT NULL,
  PRIMARY KEY (`sid`)
);

-- --------------------------------------------------------------------------------
-- Routine DDL
-- Note: comments before and after the routine body will not be stored by the server
-- --------------------------------------------------------------------------------
DELIMITER $$

CREATE DEFINER=`root`@`localhost` PROCEDURE `getEdges`(art varchar(255), sid varchar(255), dmax int, sd varchar(25), ed varchar(25))
BEGIN
    DECLARE currentUser varchar(255);
    DECLARE lastUser varchar(255);
    DECLARE currentTimestamp datetime;
    DECLARE lastTimestamp datetime;
    DECLARE lastWeekTimestamp datetime;
    DECLARE weekCount int;
    DECLARE currentSum int;
    DECLARE currentSumSqr int;
    DECLARE weeklyMean float;
    DECLARE weeklyVariance float;
    DECLARE dt int;
    DECLARE w float;
    DECLARE wdt float;
    DECLARE done INT DEFAULT FALSE;
    
    DECLARE cur1 CURSOR FOR SELECT user, sum, sumsqr FROM sigma;
    DECLARE cur CURSOR FOR SELECT userid, timestamp FROM wpdump.entry
    WHERE article = art
    AND timestamp >= COALESCE(STR_TO_DATE(sd, '%Y-%m-%d'), (SELECT min(timestamp) FROM wpdump.entry WHERE article = art))
    AND timestamp <= COALESCE(STR_TO_DATE(ed, '%Y-%m-%d'), (SELECT max(timestamp) FROM wpdump.entry WHERE article = art))
    ORDER BY timestamp;
    
    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
    SET lastUser = '';
    SET w = 0;
    SET weekCount = 0;
    SET lastWeekTimestamp = 0;
    
    SET SQL_SAFE_UPDATES = 0;
    
    DELETE FROM edge WHERE edge.sid = sid AND article = art;
    
    CREATE TEMPORARY TABLE IF NOT EXISTS sigma (user varchar(255), edits int, sum int, sumsqr int, PRIMARY KEY (`user`));
    
    OPEN cur;
    read_loop: LOOP
        #SET done = FALSE;
        FETCH cur INTO currentUser, currentTimestamp;
        
        IF done THEN
          LEAVE read_loop;
        END IF;
        
        IF currentUser <> lastUser AND lastUser <> '' THEN
            IF lastWeekTimestamp = 0 THEN
                SET lastWeekTimestamp = currentTimestamp;
            END IF;
            SELECT count(*) INTO @w FROM sigma WHERE user = currentUser;
            IF @w = 0 THEN
                INSERT INTO sigma VALUES (currentUser, 0, 0, 0);
            END IF;
            
            SET dt = timestampdiff(second, lastTimestamp, currentTimestamp);
            IF dt < dmax THEN
                SET wdt = 1 - (dt / dmax);
            ELSE
                SET wdt = 0;
            END IF;
            
            SELECT count(*) INTO @w FROM edge WHERE fromuser = currentUser AND touser = lastUser
            AND article = art AND edge.sid = sid;
            IF @w > 0 THEN
                #SELECT weight INTO @w FROM tmp WHERE fromuser = currentUser AND touser = lastUser;
                #UPDATE tmp SET weight = (@w + wdt) WHERE fromuser = currentUser AND touser = lastUser;
                UPDATE edge
                SET weight = (weight + wdt)
                WHERE fromuser = currentUser AND touser = lastUser
                AND article = art AND edge.sid = sid;
            ELSE
                IF wdt <> 0 THEN
                    INSERT INTO edge VALUES (currentUser, lastUser, wdt, art, sid);
                END IF;
            END IF;
        END IF;
        
        UPDATE sigma SET edits = edits + 1 WHERE user = currentUser;
        
        IF timestampdiff(day, lastWeekTimestamp, currentTimestamp) >= 7 THEN
            SET weekCount = weekCount + 1;
            
            UPDATE sigma SET sum = sum + edits WHERE user = currentUser;
            UPDATE sigma SET sumsqr = sumsqr + edits*edits WHERE user = currentUser;
            UPDATE sigma SET edits = 0 WHERE user = currentUser;
            
            SET lastWeekTimestamp = currentTimestamp;
        END IF;
        
        SET lastUser = currentUser;
        SET lastTimestamp = currentTimestamp;
    END LOOP;
    CLOSE cur;
    
    SET done = FALSE;
    
    #CREATE TEMPORARY TABLE weekcount (count int);
    #INSERT INTO weekcount VALUES (weekCount);
    
    OPEN cur1;
    read_loop: LOOP
        FETCH cur1 INTO currentUser, currentSum, currentSumSqr;
        
        IF done THEN
          LEAVE read_loop;
        END IF;

        IF weekCount > 0 THEN
            SET weeklyMean = currentSum / weekCount;
            SET weeklyVariance = (currentSumSqr - currentSum * weeklyMean) / weekCount;
            
            IF weeklyMean > 0 THEN
                INSERT INTO weeklyedits VALUES (currentUser, art, SQRT(weeklyVariance)/weeklyMean);
            END IF;
        END IF;
    END LOOP;
    CLOSE cur1;
    
    DROP TEMPORARY TABLE IF EXISTS sigma;
    
    SET SQL_SAFE_UPDATES = 1;
END



- Get a Wikipedia stub file from http://dumps.wikimedia.org/

- Run 'perl parse.pl CONNECTION ARTICLES DTMAX DUMPFILE' with
    CONNECTION : database credentials in the form "dbname,dbhost,dbuser,dbpass"
    ARTICLES : page titles whose history you want to analyse as comma-separated list, e.g. "Alan Smithee, Ang Lee, Aussagenlogik" (use those double quotes!)
    DTMAX : the maximum time difference between edits (as integer)
    DUMPFILE : path to the Wikipedia dump file

2) Eigenvalue generator

The 'evgen' tool calculated eigenvalues and associated eigenvectors and is automatically called by the php script.

- Run 'evgen "Articlename" "SessionID" ' (for a debug html output add a third parameter, e.g. 'evgen Articlename xyz debug')

